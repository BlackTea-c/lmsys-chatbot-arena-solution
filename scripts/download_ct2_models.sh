# ct2-transformers-converter --model meta-llama/Llama-2-7b-chat-hf --output_dir /mnt/one/ct2_models/meta-llama/Llama-2-7b-chat-hf --quantization int8 --force
# ct2-transformers-converter --model meta-llama/Llama-2-13b-chat-hf --output_dir /mnt/one/ct2_models/meta-llama/Llama-2-13b-chat-hf --quantization int8
# # ct2-transformers-converter --model meta-llama/Llama-2-70b-chat-hf --output_dir /mnt/one/ct2_models/meta-llama/Llama-2-70b-chat-hf --quantization int8
# ct2-transformers-converter --model HuggingFaceH4/zephyr-7b-beta --output_dir /mnt/one/ct2_models/HuggingFaceH4/zephyr-7b-beta --quantization int8
# ct2-transformers-converter --model lmsys/vicuna-33b-v1.3 --output_dir /mnt/one/ct2_models/lmsys/vicuna-33b-v1.3 --quantization int8
# ct2-transformers-converter --model lmsys/vicuna-13b-v1.3 --output_dir /mnt/one/ct2_models/lmsys/vicuna-13b-v1.3 --quantization int8
# ct2-transformers-converter --model mistralai/Mistral-7B-Instruct-v0.3 --output_dir /mnt/one/ct2_models/mistralai/Mistral-7B-Instruct-v0.3 --quantization int8
# ct2-transformers-converter --model "01-ai/Yi-1.5-34B-Chat" --output_dir /mnt/one/ct2_models/01-ai/Yi-1.5-34B-Chat --quantization int8